{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a1d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "!pip install split-folders\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# 파일 경로 설정\n",
    "metadata_path = 'C:/Users/Denny/Downloads/iot_ewha/metadata.csv'\n",
    "source_dir = 'C:/Users/Denny/Downloads/iot_ewha/faces_224'\n",
    "base_dir = 'C:/Users/Denny/Downloads/iot_img/'  # 이 경로는 현재 작업 중인 주피터 노트북의 경로입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0abd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 주석으로 처리한 코드는 faces_224가 들어있는 폴더 A에서 REAL이랑 FAKE로 폴더를 나누어놓은 base 폴더인 폴더 B로 이미지 데이터 복사하는 코드이므로 이미 복사해두었으면 굳이 안 돌리셔도 됩니다!\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# 'train' 및 'val' 폴더 안에 'FAKE'와 'REAL' 서브폴더 생성\n",
    "for subset in ['train', 'val', 'test']:\n",
    "    for category in ['FAKE', 'REAL']:\n",
    "        dir_path = os.path.join(base_dir, subset, category)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        \n",
    "# 이미지 파일 가져오기\n",
    "image_files = os.listdir(source_dir)\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# 데이터 분할 및 복사\n",
    "split_ratio = {'train': 0.7, 'val': 0.2, 'test': 0.1}\n",
    "num_files = len(image_files)\n",
    "\n",
    "start_idx = 0\n",
    "for subset, ratio in split_ratio.items():\n",
    "    end_idx = start_idx + int(num_files * ratio)\n",
    "    subset_files = image_files[start_idx:end_idx]\n",
    "    start_idx = end_idx\n",
    "    \n",
    "    for filename in subset_files:\n",
    "        label = 'REAL' if filename.startswith('real') else 'FAKE'\n",
    "        source_file = os.path.join(source_dir, filename)\n",
    "        target_folder = os.path.join(base_dir, subset, label)\n",
    "        shutil.copy(source_file, target_folder)\n",
    "\n",
    "print(\"Data splitting and copying completed successfully!\")\n",
    "\n",
    "# metadata.csv 로드\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# 파일을 무작위로 선택하여 train, val, test로 분할\n",
    "for _, row in metadata.iterrows():\n",
    "    # 분할할 폴더 선택\n",
    "    if row['videoname'][:2] == 'az':\n",
    "        subset = 'train'\n",
    "    elif row['videoname'][:2] == 'gk':\n",
    "        subset = 'val'\n",
    "    else:\n",
    "        subset = 'test'\n",
    "    \n",
    "    # 대상 경로 설정\n",
    "    target_folder = os.path.join(base_dir, subset, row['label'])\n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "    \n",
    "    # 소스 파일 경로\n",
    "    source_file = os.path.join(source_dir, row['videoname'][:-4] + '.jpg')\n",
    "    \n",
    "    # 파일 복사\n",
    "    shutil.copy(source_file, target_folder)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c640bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 데이터 증강 설정\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    horizontal_flip = True, vertical_flip = True, zoom_range = 0.1,\n",
    "    shear_range = 0.1, width_shift_range = 0.2, height_shift_range = 0.2, rotation_range = 90,\n",
    ")\n",
    "test_data_generator = ImageDataGenerator()\n",
    "\n",
    "# 데이터 로딩\n",
    "train_data = train_data_generator.flow_from_directory(os.path.join(base_dir, 'train'), target_size=(128, 128), batch_size=32, class_mode='binary', shuffle=True)\n",
    "test_data = test_data_generator.flow_from_directory(os.path.join(base_dir, 'test'), target_size=(128, 128), batch_size=32, class_mode='binary', shuffle=True)\n",
    "val_data = test_data_generator.flow_from_directory(os.path.join(base_dir, 'val'), target_size=(128, 128), batch_size=32, class_mode='binary', shuffle=True)\n",
    "\n",
    "# 클래스 레이블 확인\n",
    "labels = train_data.class_indices\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",be
   "id": "39c647c1",
   "metadata": {},
   "source": [
    "### ImageDataGenerator does not really assign values to an array, it just hold pointers. Because of that every learning step CPU perform reading operations. This very slows learning speed. We will store data in numpy array type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552a294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_array_from_datagen(generator):\n",
    "    x = []\n",
    "    y = []\n",
    "    generator.reset()\n",
    "    for i in range(generator.__len__()):\n",
    "        a, b = generator.next()\n",
    "        x.append(a)\n",
    "        y.append(b)\n",
    "    x = np.concatenate(x, axis=0)  # 이미지 배열을 하나로 합칩니다.\n",
    "    y = np.concatenate(y, axis=0)  # 레이블 배열을 하나로 합칩니다.\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    return x, y\n",
    "\n",
    "X_train, y_train = get_array_from_datagen(train_data)\n",
    "X_test, y_test = get_array_from_datagen(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 128, 128, 3)\n",
    "X_test = X_test.reshape(-1, 128, 128, 3)\n",
    "y_train = y_train.reshape(-1, 3)\n",
    "y_test = y_test.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c578176",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델 돌리시려면 resampling 하셔야 해요!\n",
    "# `y_train`의 샘플 수에 맞추기 위해 `X_train`에서 무작위로 샘플 선택\n",
    "indices = np.random.choice(X_train.shape[0], y_train.shape[0], replace=False)\n",
    "X_train_resampled = X_train[indices]    # `y_train`은 이미 목표 샘플 수에 맞춰져 있음\n",
    "\n",
    "indices = np.random.choice(X_test.shape[0], y_test.shape[0], replace=False)\n",
    "X_test_resampled = X_test[indices]\n",
    "\n",
    "# 선택된 인덱스로부터 데이터셋 다시 할당\n",
    "X_resampled_train = X_train[:6000,:,:,:]\n",
    "y_resampled_train = y_train[:6000,:]\n",
    "\n",
    "X_resampled_test = X_test[:2000,:,:,:]\n",
    "y_resampled_test = y_test[:2000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5423c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "\n",
    "input_shape = (128, 128, 3)\n",
    "class_num = len(labels)\n",
    "\n",
    "learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor = \"val_accuracy\",\n",
    "    factor = 0.5,\n",
    "    patience = 3,\n",
    "    verbose = 1,\n",
    "    min_lr = 0.00001\n",
    ")\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519402f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_ResNet101 = tf.keras.applications.ResNet101(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b09eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ResNet101 = keras.Sequential([\n",
    "    base_model_ResNet101,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(128, activation='swish'),  # 추가 Dense 레이어\n",
    "    keras.layers.Dropout(0.5),  # Dropout 레이어 추가\n",
    "    keras.layers.Dense(64, activation='mish'),  # 추가 Dense 레이어\n",
    "    keras.layers.Dropout(0.5), \n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model_ResNet101.compile(\n",
    "    optimizer=\"Adam\",\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history_ResNet101 = model_ResNet101.fit(\n",
    "    X_train_resampled, y_train,\n",
    "    validation_data=(X_test_resampled, y_test),\n",
    "    epochs=5,\n",
    "    callbacks = [learning_rate_reduction, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe961b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_ResNet101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babdcf9b",
   "metadata": {},
   "source": [
    "## We will check recall, precision and f1-score value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaed58b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet101(include_top=False)\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=\"Adam\",\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    X_resampled_train, y_resampled_train,\n",
    "    validation_data=(X_resampled_test, y_resampled_test),\n",
    "    epochs=10,\n",
    "    callbacks = [learning_rate_reduction],\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618d9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test.argmax(axis = 1), model.predict(X_test).argmax(axis = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56f3aa2",
   "metadata": {},
   "source": [
    "Okay let's look some predictions on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600fd29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "os.mkdir(\"./resnet101/test_data\")\n",
    "os.mkdir(\"./resnet101/test_data/REAL\")\n",
    "os.mkdir(\"./resnet101/test_data/FAKE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53ff923",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "names = []\n",
    "k = 0\n",
    "\n",
    "k = 0\n",
    "path = \"./val/REAL\"\n",
    "for i in os.listdir(path):\n",
    "    paths.append(path + \"/\" + i)\n",
    "    names.append(\"REAL\")\n",
    "    copyfile(path + \"/\" + i, f\"resnet101/test_data/REAL/{i}\")\n",
    "    k += 1\n",
    "    if k == 8:\n",
    "        break\n",
    "        \n",
    "path = \"./val/FAKE\"\n",
    "k = 0\n",
    "for i in os.listdir(path):\n",
    "    paths.append(path + \"/\" + i)\n",
    "    names.append(\"FAKE\")\n",
    "    copyfile(path + \"/\" + i,  f\"resnet101/test_data/FAKE/{i}\")\n",
    "    k += 1\n",
    "    if k == 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58180501",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_2 = test_data_generator.flow_from_directory(\"./resnet101/test_data\", target_size = (128,128), batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca20f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)\n",
    "labels_2 = {}\n",
    "for k,v in labels.items():\n",
    "    labels_2[v] = k\n",
    "labels_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b50638",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data_2).argmax(axis = 1)\n",
    "pred_label = []\n",
    "for i in predictions:\n",
    "    pred_label.append(labels_2[i])\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e146220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "fig, axes = plt.subplots(nrows=5,\n",
    "                         ncols=5,\n",
    "                         figsize=(20, 20),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(paths[i]))\n",
    "    ax.set_title(f\"PREDICTION:{pred_label[i]}\")\n",
    "    ax.set_xlabel(f\"DATA : {names[i]}\")\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80162b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
